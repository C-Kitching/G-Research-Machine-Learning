{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Introduction to Decision Trees\n", "\n", "In this notebook, we will apply a decision tree classifier to marketing data using the machine learning library `scikit-learn` in Python. \n", "\n", "We will first walk you quickly through the data processing using the `pandas` library. Feel free to read through and review it, but this is not important for today's session so don't worry if it looks unfamiliar (thoguh do feel free to ask questions!)\n", "\n", "The important bits are the two \"Hands on\" sections, where you will fit the decisition tree classifier to the training data and evaluate it on the test data, and then where you will experiment with the model parameters."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Guided walkthrough - data processing\n", "\n", "We first import the packages that we will use during the practical:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### The dataset"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["The dataset is available in the `data/` directory, but it can be also downloaded from [here](https://archive.ics.uci.edu/ml/datasets/bank+marketing). It consists of data from marketing campaigns of a Portuguese bank. We will try to build a classifier that can predict whether or not the client targeted by the campaign ended up subscribing to a term deposit (column `y`).\n", "\n", "We will first load the file `data/bank-marketing.csv` as a `pandas` DataFrame `df` and check the distribution of the target `y`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["df = pd.read_csv(\"data/bank-marketing.csv\",sep=\";\")\n", "df['y'].value_counts()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["The dataset is imbalanced, so we will need to keep that in mind when building our models!"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Now we split the data into the feature matrix `X` (all features except `y`) and the target vector `y`, making sure that you convert `yes` to `1` and `no` to `0`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Get X, y\n", "y = df[\"y\"].map({\"no\":0, \"yes\":1})\n", "X = df.drop(\"y\", axis=1)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Here is the list of features in our `X` matrix:"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["| | | |\n", "| --- | --- | --- |\n", "age | | numeric \n", "job | type of job | categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown'\n", "marital | marital status | categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed\n", "education | | categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown'\n", "default | has credit in default? | categorical: 'no','yes','unknown'\n", "housing | has housing loan? | categorical: 'no','yes','unknown'\n", "loan | has personal loan? | categorical: 'no','yes','unknown'\n", "contact | contact communication type | categorical: 'cellular','telephone'\n", "month | last contact month of year | categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec'\n", "day_of_week | last contact day of the week | categorical: 'mon','tue','wed','thu','fri'\n", "duration | last contact duration, in seconds | numeric. Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n", "campaign | number of contacts performed during this campaign and for this client | numeric, includes last contact\n", "pdays | number of days that passed by after the client was last contacted from a previous campaign | numeric; 999 means client was not previously contacted\n", "previous | number of contacts performed before this campaign and for this client | numeric\n", "poutcome | outcome of the previous marketing campaign | categorical: 'failure','nonexistent','success'\n", "emp.var.rate | employment variation rate - quarterly indicator | numeric\n", "cons.price.idx | consumer price index - monthly indicator | numeric\n", "cons.conf.idx | consumer confidence index - monthly indicator | numeric\n", "euribor3m | euribor 3 month rate - daily indicator | numeric \n", "nr.employed | number of employees - quarterly indicator | numeric"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Note the comment about the `duration` feature. We will exclude it from our analysis."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["X.drop(\"duration\", inplace=True, axis=1)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Now we can check the types of all our features. We see that some seem to be categorical whilst others are numerical. We will keep two lists, one for each type, so we can preprocess them differently."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["X.dtypes"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# when there is a third class \"unknown\", we'll process the feature as non-binary categorical\n", "num_features = [\"age\", \"campaign\", \"pdays\", \"previous\", \"emp.var.rate\", \n", "                \"cons.price.idx\", \"cons.conf.idx\",\"euribor3m\", \"nr.employed\"]\n", "\n", "cat_features = [\"job\", \"marital\", \"education\",\"default\", \"housing\", \"loan\",\n", "                \"contact\", \"month\", \"day_of_week\", \"poutcome\"]"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### One-hot encoding on categorical features"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["The `sklearn` implementation of decision trees cannot work directly with categorical features, so we need to make sure our dataset contains only numbers. Consequently, we will need to transform our categorical features into one-hot encoded features.\n", "\n", "To do so, we use `pd.get_dummies` on our DataFrame (select only the categorical features - we already have them stored in the variable `cat_features`) to generate the new columns.\n", "\n", "We assign the new DataFrame to a variable `X_categorical`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["X_categorical = pd.get_dummies(X[cat_features])"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Finally, we create a Dataframe with only our numerical features (we have their names stored in the variable `num_features`) from `X` together with the `X_categorical` DataFrame.\n", "\n", "We use `pd.concat` (making sure to specify the correct axis!) and call the new DataFrame `X_processed`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["X_processed = pd.concat([X[num_features], X_categorical], axis=1)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Splitting the data into training and test sets"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["The last step is to split the data (use `X_processed`) into a training set and test set. Here we are dealing with an imbalanced dataset, so it is important to enforce stratification. We will use the argument `stratify` from `train_test_split` to do so.\n", "\n", "We call the new variables `X_train`, `X_test`, `y_train`, and `y_test`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(\n", "    X_processed,\n", "    y,\n", "    test_size=.3,\n", "    random_state=42,\n", "    stratify=y\n", ")"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Hands on Part 1 - Training a decision tree in scikit-learn\n", "\n", "Now that we have done our preprocessing and our data is ready, we can get hands on and start doing some machine learning!\n", "\n", "We will begin by training our first decision tree. We will use `DecisionTreeClassifier` from `sklearn.tree`.\n", "\n", "For now we will keep our tree unconstrained with:\n", "- `max_depth=None`\n", "- `min_samples_split=2`"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Create a new decision tree, assigning it to the variable `dtc`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\n", "\n", "# Your code here...\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Now fit the model on the training set:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Execute the cell below to display the tree in the notebook, what do you observe?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn import tree\n", "\n", "plt.figure(figsize=(200, 20))\n", "tree.plot_tree(dtc, \n", "               filled=True, \n", "               rounded=True,\n", "               max_depth=6,\n", "               proportion=True,\n", "               fontsize=10,\n", "               feature_names=X_train.columns)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Compute the accuracy of the model on the training data and then on the test data, what can you tell?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["We can tell a lot more about what is going on with a deterministic (0-1) classifier by looking at the *confusion matrix*. \n", "\n", "It shows not only *how many* predictions our model gets right, but also *which* ground-truth classes the model is classifying correctly and incorrectly. \n", "\n", "Use the code below to display the confusion matrix of your model on the test data, and see if you can understand what it reveals about the model performance."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n", "\n", "ConfusionMatrixDisplay(confusion_matrix(y_test, dtc.predict(X_test))).plot()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Part 2: Decisition Tree parameters"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Parameter tuning"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["In order to prevent overfitting, we need to regularise (constrain) our model during model fitting. We can do this using the *model parameters*. \n", "\n", "To change the parameters of the existing tree classifier `dtc`, you can use `set_params` on it with the name and values you want to update (for example `max_depth=6`).\n", "\n", "Try some different values for `max_depth`. You can also experiment with other parameters!\n", "\n", "Don't forget to re-train the tree after changing the parameters."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Let's check the accuracy on both the train and the test set. Is it better than before?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Try experimenting with the parameters through trial and error to achieve the best accuracy on the test set. \n", "\n", "Don't worry about a grid-search or automating the search, the results aren't too important here!"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Once you are happy with your paramters, you can visualise the resulting tree:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["plt.figure(figsize=(120, 12))\n", "tree.plot_tree(dtc, \n", "               filled=True, \n", "               rounded=True,\n", "               max_depth=6,\n", "               proportion=True,\n", "               fontsize=10,\n", "               feature_names=X_train.columns)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["How does it compare to the one above?\n", "\n", "\n", "Let's also have a look at the confusion matrix again:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n", "\n", "ConfusionMatrixDisplay(confusion_matrix(y_test, dtc.predict(X_test))).plot()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Our accuracy has improved, but what has happened to the confusion matrix? \n", "\n", "*Hint:* look closely at the number of predicted labels of class 1 vs the number of true labels of class 1."]}]}